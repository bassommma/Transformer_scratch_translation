{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10821422,"sourceType":"datasetVersion","datasetId":6718849},{"sourceId":10885354,"sourceType":"datasetVersion","datasetId":6764182},{"sourceId":10887585,"sourceType":"datasetVersion","datasetId":6765500},{"sourceId":10933598,"sourceType":"datasetVersion","datasetId":6798791}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\n# !pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 altair GPUtil\n# !python -m spacy download de_core_news_sm\n# !python -m spacy download en_core_web_sm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.817209Z","iopub.execute_input":"2025-03-06T05:06:07.817521Z","iopub.status.idle":"2025-03-06T05:06:07.821046Z","shell.execute_reply.started":"2025-03-06T05:06:07.817497Z","shell.execute_reply":"2025-03-06T05:06:07.820218Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# !pip uninstall -y wandb protobuf\n\n# # 2. Install specific versions known to work together\n# !pip install protobuf==3.20.0\n# !pip install wandb==0.15.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.841477Z","iopub.execute_input":"2025-03-06T05:06:07.841691Z","iopub.status.idle":"2025-03-06T05:06:07.844635Z","shell.execute_reply.started":"2025-03-06T05:06:07.841673Z","shell.execute_reply":"2025-03-06T05:06:07.843991Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"import os\nfrom os.path import exists\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.functional import log_softmax, pad\nimport math\nimport copy\nimport time\nfrom torch.optim.lr_scheduler import LambdaLR\nimport pandas as pd\nimport altair as alt\nfrom torchtext.data.functional import to_map_style_dataset\nfrom torch.utils.data import DataLoader\nfrom torchtext.vocab import build_vocab_from_iterator\nimport torchtext.datasets as datasets\nimport spacy\nimport GPUtil\nimport warnings\nfrom torch.utils.data.distributed import DistributedSampler\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\nimport numpy as np\n# Set to False to skip notebook execution (e.g. for debugging)\nwarnings.filterwarnings(\"ignore\")\nRUN_EXAMPLES = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.848106Z","iopub.execute_input":"2025-03-06T05:06:07.848381Z","iopub.status.idle":"2025-03-06T05:06:07.858701Z","shell.execute_reply.started":"2025-03-06T05:06:07.848361Z","shell.execute_reply":"2025-03-06T05:06:07.858032Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"class EncoderDecoder(nn.Module):\n    def __init__(self,encoder,decoder,src_embed,tgt_embed,generator):\n        super(EncoderDecoder,self).__init__()\n        self.encoder = encoder \n        self.decoder = decoder \n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed \n        self.generator = generator \n        \n    def forward(self,src,tgt,src_mask,tgt_mask):\n        return self.generator(self.decode(self.encode(src,src_mask), src_mask,tgt,tgt_mask))\n        \n    def encode(self,src,src_mask):\n        return self.encoder(self.src_embed(src), src_mask)\n        \n    def decode(self,memory,src_mask,tgt,tgt_mask):\n        return self.decoder(self.tgt_embed(tgt),memory,src_mask,tgt_mask)\n      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.859809Z","iopub.execute_input":"2025-03-06T05:06:07.860101Z","iopub.status.idle":"2025-03-06T05:06:07.875054Z","shell.execute_reply.started":"2025-03-06T05:06:07.860077Z","shell.execute_reply":"2025-03-06T05:06:07.874505Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self,model_size,vocab):\n        super(Generator,self).__init__()\n        self.proj = nn.Linear(model_size,vocab)\n        \n    def forward(self,x):\n        return F.log_softmax(self.proj(x), dim=-1)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.876152Z","iopub.execute_input":"2025-03-06T05:06:07.876444Z","iopub.status.idle":"2025-03-06T05:06:07.887305Z","shell.execute_reply.started":"2025-03-06T05:06:07.876424Z","shell.execute_reply":"2025-03-06T05:06:07.886533Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"def clones (module,N):\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.888085Z","iopub.execute_input":"2025-03-06T05:06:07.888351Z","iopub.status.idle":"2025-03-06T05:06:07.902304Z","shell.execute_reply.started":"2025-03-06T05:06:07.888324Z","shell.execute_reply":"2025-03-06T05:06:07.901598Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self,features,eps=1e-6):\n        super().__init__()\n        self.a = nn.Parameter(torch.ones(features))\n        self.b = nn.Parameter(torch.zeros(features))\n        self.eps=eps\n        \n    def forward(self,x):\n        mean=x.mean(-1,keepdim=True)\n        std=x.std(-1,keepdim=True)\n        return self.a*(x-mean)/(std+self.eps)+self.b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.903493Z","iopub.execute_input":"2025-03-06T05:06:07.903775Z","iopub.status.idle":"2025-03-06T05:06:07.915058Z","shell.execute_reply.started":"2025-03-06T05:06:07.903747Z","shell.execute_reply":"2025-03-06T05:06:07.914396Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,layer,N):\n        super().__init__()\n        self.layers = clones(layer,N)\n        self.norm = LayerNorm(layer.size)\n    def forward(self,x,mask):\n        for layer in self.layers:\n            x=layer(x,mask)\n        return self.norm(x)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.915782Z","iopub.execute_input":"2025-03-06T05:06:07.915962Z","iopub.status.idle":"2025-03-06T05:06:07.931819Z","shell.execute_reply.started":"2025-03-06T05:06:07.915946Z","shell.execute_reply":"2025-03-06T05:06:07.931136Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"class SubLayerConection(nn.Module):\n    def __init__(self,features,dropout):\n        super().__init__()\n        self.norm = LayerNorm(features)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self,x,sublayer):\n        return x + self.dropout(sublayer(self.norm(x)))\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.971146Z","iopub.execute_input":"2025-03-06T05:06:07.971446Z","iopub.status.idle":"2025-03-06T05:06:07.975619Z","shell.execute_reply.started":"2025-03-06T05:06:07.971423Z","shell.execute_reply":"2025-03-06T05:06:07.974732Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self,size,self_attn,feed_forward,dropout):\n        super().__init__()\n        self.self_attn = self_attn\n        self.feed_forward = feed_forward \n        self.dropout = dropout \n        self.size = size \n\n        self.sublayersconections = clones(SubLayerConection(size,dropout),2)\n\n    def forward(self,x,mask):\n        x = self.sublayersconections[0](x,lambda x:self.self_attn(x,x,x,mask))\n        x = self.sublayersconections[1](x,self.feed_forward)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.976716Z","iopub.execute_input":"2025-03-06T05:06:07.976992Z","iopub.status.idle":"2025-03-06T05:06:07.988954Z","shell.execute_reply.started":"2025-03-06T05:06:07.976965Z","shell.execute_reply":"2025-03-06T05:06:07.988228Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self,layer,N):\n        super().__init__()\n        self.layers = clones(layer,N)\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self,x,memory,src_mask,tgt_mask):\n        for layer in self.layers:\n            x = layer(x,memory,src_mask,tgt_mask)\n        return self.norm(x)\n            \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:07.994652Z","iopub.execute_input":"2025-03-06T05:06:07.994884Z","iopub.status.idle":"2025-03-06T05:06:08.002431Z","shell.execute_reply.started":"2025-03-06T05:06:07.994857Z","shell.execute_reply":"2025-03-06T05:06:08.001595Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def subsequent_mask(size):\n    mask_size=(1,size,size)\n    mask=np.triu(np.ones(mask_size),k=1).astype('uint8')\n    mask = torch.from_numpy(mask==0)\n    return mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.003392Z","iopub.execute_input":"2025-03-06T05:06:08.003592Z","iopub.status.idle":"2025-03-06T05:06:08.015385Z","shell.execute_reply.started":"2025-03-06T05:06:08.003574Z","shell.execute_reply":"2025-03-06T05:06:08.014744Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self,size,self_attn,cross_attn,feed_forward,dropout):\n        super().__init__()\n        self.self_attn = self_attn\n        self.cross_attn = cross_attn\n        self.feed_forward = feed_forward\n        self.size = size\n        self.dropout = dropout\n        self.subs = clones(SubLayerConection(size,dropout),3)\n    def forward(self,x,memory,src_mask,tgt_mask):\n        m = memory\n        x=self.subs[0](x,lambda x:self.self_attn(x,x,x,tgt_mask))\n        x=self.subs[1](x,lambda x:self.cross_attn(x,m,m,src_mask))\n        x=self.subs[2](x,self.feed_forward)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.016909Z","iopub.execute_input":"2025-03-06T05:06:08.017111Z","iopub.status.idle":"2025-03-06T05:06:08.028753Z","shell.execute_reply.started":"2025-03-06T05:06:08.017093Z","shell.execute_reply":"2025-03-06T05:06:08.028060Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"subsequent_mask(4)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.029739Z","iopub.execute_input":"2025-03-06T05:06:08.029931Z","iopub.status.idle":"2025-03-06T05:06:08.044119Z","shell.execute_reply.started":"2025-03-06T05:06:08.029914Z","shell.execute_reply":"2025-03-06T05:06:08.043401Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"tensor([[ True, False, False, False],\n        [ True,  True, False, False],\n        [ True,  True,  True, False],\n        [ True,  True,  True,  True]])"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"subsequent_mask(4)[0][0][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.044939Z","iopub.execute_input":"2025-03-06T05:06:08.045118Z","iopub.status.idle":"2025-03-06T05:06:08.056010Z","shell.execute_reply.started":"2025-03-06T05:06:08.045103Z","shell.execute_reply":"2025-03-06T05:06:08.055395Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"tensor(False)"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"  data =    pd.DataFrame([\n                \n                {\n                    \"Subsequent Mask\": subsequent_mask(20)[0][x, y].item(),\n                    \"Window\": y,\n                    \"Masking\": x,\n                }\n            \n            for y in range(20)\n            for x in range(20)\n                       \n                         ]\n                        )\n  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.087009Z","iopub.execute_input":"2025-03-06T05:06:08.087308Z","iopub.status.idle":"2025-03-06T05:06:08.107544Z","shell.execute_reply.started":"2025-03-06T05:06:08.087286Z","shell.execute_reply":"2025-03-06T05:06:08.106762Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.108490Z","iopub.execute_input":"2025-03-06T05:06:08.108706Z","iopub.status.idle":"2025-03-06T05:06:08.116947Z","shell.execute_reply.started":"2025-03-06T05:06:08.108688Z","shell.execute_reply":"2025-03-06T05:06:08.116254Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"     Subsequent Mask  Window  Masking\n0               True       0        0\n1               True       0        1\n2               True       0        2\n3               True       0        3\n4               True       0        4\n..               ...     ...      ...\n395            False      19       15\n396            False      19       16\n397            False      19       17\n398            False      19       18\n399             True      19       19\n\n[400 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subsequent Mask</th>\n      <th>Window</th>\n      <th>Masking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>True</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>True</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>False</td>\n      <td>19</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>False</td>\n      <td>19</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>False</td>\n      <td>19</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>False</td>\n      <td>19</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>True</td>\n      <td>19</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"chart=alt.Chart(data).mark_rect().properties(height=250, width=250).encode(\nx=alt.X(\"Window:O\"),\ny=alt.Y(\"Masking:O\"),\ncolor=alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\"))).interactive()\nchart","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.121530Z","iopub.execute_input":"2025-03-06T05:06:08.121736Z","iopub.status.idle":"2025-03-06T05:06:08.141841Z","shell.execute_reply.started":"2025-03-06T05:06:08.121718Z","shell.execute_reply":"2025-03-06T05:06:08.141067Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/html":"\n<style>\n  #altair-viz-e1bfb372a3964f1ea52f086d15be0218.vega-embed {\n    width: 100%;\n    display: flex;\n  }\n\n  #altair-viz-e1bfb372a3964f1ea52f086d15be0218.vega-embed details,\n  #altair-viz-e1bfb372a3964f1ea52f086d15be0218.vega-embed details summary {\n    position: relative;\n  }\n</style>\n<div id=\"altair-viz-e1bfb372a3964f1ea52f086d15be0218\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-e1bfb372a3964f1ea52f086d15be0218\") {\n      outputDiv = document.getElementById(\"altair-viz-e1bfb372a3964f1ea52f086d15be0218\");\n    }\n\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      let deps = [\"vega-embed\"];\n      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-b1e327ac8c79b2564320d4813313cbb8\"}, \"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Subsequent Mask\", \"scale\": {\"scheme\": \"viridis\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"Window\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Masking\", \"type\": \"ordinal\"}}, \"height\": 250, \"params\": [{\"name\": \"param_3\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"width\": 250, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-b1e327ac8c79b2564320d4813313cbb8\": [{\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 1, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 17}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 19, \"Masking\": 19}]}}, {\"mode\": \"vega-lite\"});\n</script>","text/plain":"alt.Chart(...)"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"def Attention(query,key,value,mask=None,dropout=None):\n    size = query.size(-1)\n    \n    scores = torch.matmul(query,key.transpose(-2,-1))/math.sqrt(size)\n    if mask is not None:\n        mask = mask.unsqueeze(1) if mask.dim() == 3 else mask\n        scores = scores.masked_fill(mask==0,float('-inf'))\n    p_atten = scores.softmax(dim=-1)\n    if dropout is not None:\n        p_atten=dropout(p_atten)\n    \n    x = torch.matmul(p_atten,value)\n        \n    return x ,p_atten\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.142760Z","iopub.execute_input":"2025-03-06T05:06:08.142965Z","iopub.status.idle":"2025-03-06T05:06:08.147594Z","shell.execute_reply.started":"2025-03-06T05:06:08.142947Z","shell.execute_reply":"2025-03-06T05:06:08.146948Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"class MultiHeadedAttention(nn.Module):\n    def __init__(self,head,model_size,dropout=0.1):\n        super().__init__()\n\n        assert model_size%head==0\n        self.dk = model_size//head\n        self.linears = clones(nn.Linear(model_size,model_size),4)\n        self.dropout = nn.Dropout(p=dropout)\n        self.head = head\n    def forward(self,query,key,value,mask=None):\n        n_batches=query.size(0)\n    \n        if mask is not None:\n            mask=mask.unsqueeze(1)\n        \n        query,key,value =[\n            linear(x).view(n_batches,-1,self.head,self.dk).transpose(1,2)\n        \n            for linear,x in zip(self.linears,(query,key,value))\n            ]\n        x, attention_weights = Attention(query,key,value,mask=mask,dropout=self.dropout)\n\n        x = x.transpose(1,2).contiguous().view(n_batches,-1,self.head*self.dk)\n        del query\n        del key \n        del value \n        return self.linears[-1](x)\n    \n    \n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.182881Z","iopub.execute_input":"2025-03-06T05:06:08.183072Z","iopub.status.idle":"2025-03-06T05:06:08.188808Z","shell.execute_reply.started":"2025-03-06T05:06:08.183056Z","shell.execute_reply":"2025-03-06T05:06:08.188108Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self,model_size,dropout,max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        \n        pe = torch.zeros(max_len,model_size)\n        pos = torch.arange(0,max_len).unsqueeze(1)\n        i=torch.arange(0,model_size,2).float()\n\n        div_term = torch.exp(-i*math.log(10000)/model_size)\n        \n        pe[:,0::2] = torch.sin(pos * div_term)\n        pe[:,1::2] = torch.cos(pos * div_term)\n        \n        pe=pe.unsqueeze(0)\n        self.register_buffer(\"pe\",pe)\n        \n    def forward(self,x):\n        \n        return self.dropout(x+self.pe[:,:x.size(1),:])\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.202694Z","iopub.execute_input":"2025-03-06T05:06:08.202891Z","iopub.status.idle":"2025-03-06T05:06:08.208050Z","shell.execute_reply.started":"2025-03-06T05:06:08.202874Z","shell.execute_reply":"2025-03-06T05:06:08.207228Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"def example_positional():\n    pe = PositionalEncoding(20, 0)\n    y = pe.forward(torch.zeros(1, 100, 20))\n\n    data = pd.concat(\n        [\n            pd.DataFrame(\n                {\n                    \"embedding\": y[0, :, dim],\n                    \"dimension\": dim,\n                    \"position\": list(range(100)),\n                }\n            )\n            for dim in [4, 5, 6, 7]\n        ]\n    )\n\n    return (\n        alt.Chart(data)\n        .mark_line()\n        .properties(width=800)\n        .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n        .interactive()\n    )\n\n\nexample_positional()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.233825Z","iopub.execute_input":"2025-03-06T05:06:08.234017Z","iopub.status.idle":"2025-03-06T05:06:08.266558Z","shell.execute_reply.started":"2025-03-06T05:06:08.234000Z","shell.execute_reply":"2025-03-06T05:06:08.265930Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/html":"\n<style>\n  #altair-viz-8a343ddfe6d94e80ac6513e16df0fb15.vega-embed {\n    width: 100%;\n    display: flex;\n  }\n\n  #altair-viz-8a343ddfe6d94e80ac6513e16df0fb15.vega-embed details,\n  #altair-viz-8a343ddfe6d94e80ac6513e16df0fb15.vega-embed details summary {\n    position: relative;\n  }\n</style>\n<div id=\"altair-viz-8a343ddfe6d94e80ac6513e16df0fb15\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-8a343ddfe6d94e80ac6513e16df0fb15\") {\n      outputDiv = document.getElementById(\"altair-viz-8a343ddfe6d94e80ac6513e16df0fb15\");\n    }\n\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      let deps = [\"vega-embed\"];\n      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-74197a450f4fae82b525a303f60629a7\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"dimension\", \"type\": \"nominal\"}, \"x\": {\"field\": \"position\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"embedding\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_4\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-74197a450f4fae82b525a303f60629a7\": [{\"embedding\": 0.0, \"dimension\": 4, \"position\": 0}, {\"embedding\": 0.15782663226127625, \"dimension\": 4, \"position\": 1}, {\"embedding\": 0.3116971552371979, \"dimension\": 4, \"position\": 2}, {\"embedding\": 0.45775455236434937, \"dimension\": 4, \"position\": 3}, {\"embedding\": 0.5923377275466919, \"dimension\": 4, \"position\": 4}, {\"embedding\": 0.7120732069015503, \"dimension\": 4, \"position\": 5}, {\"embedding\": 0.813959538936615, \"dimension\": 4, \"position\": 6}, {\"embedding\": 0.8954429626464844, \"dimension\": 4, \"position\": 7}, {\"embedding\": 0.9544808864593506, \"dimension\": 4, \"position\": 8}, {\"embedding\": 0.989593505859375, \"dimension\": 4, \"position\": 9}, {\"embedding\": 0.9999006390571594, \"dimension\": 4, \"position\": 10}, {\"embedding\": 0.9851439595222473, \"dimension\": 4, \"position\": 11}, {\"embedding\": 0.94569331407547, \"dimension\": 4, \"position\": 12}, {\"embedding\": 0.8825376033782959, \"dimension\": 4, \"position\": 13}, {\"embedding\": 0.7972599267959595, \"dimension\": 4, \"position\": 14}, {\"embedding\": 0.6919978260993958, \"dimension\": 4, \"position\": 15}, {\"embedding\": 0.5693899393081665, \"dimension\": 4, \"position\": 16}, {\"embedding\": 0.4325096309185028, \"dimension\": 4, \"position\": 17}, {\"embedding\": 0.284787654876709, \"dimension\": 4, \"position\": 18}, {\"embedding\": 0.12992730736732483, \"dimension\": 4, \"position\": 19}, {\"embedding\": -0.028190065175294876, \"dimension\": 4, \"position\": 20}, {\"embedding\": -0.18560057878494263, \"dimension\": 4, \"position\": 21}, {\"embedding\": -0.3383587896823883, \"dimension\": 4, \"position\": 22}, {\"embedding\": -0.4826357960700989, \"dimension\": 4, \"position\": 23}, {\"embedding\": -0.6148146390914917, \"dimension\": 4, \"position\": 24}, {\"embedding\": -0.7315824031829834, \"dimension\": 4, \"position\": 25}, {\"embedding\": -0.8300122618675232, \"dimension\": 4, \"position\": 26}, {\"embedding\": -0.9076365828514099, \"dimension\": 4, \"position\": 27}, {\"embedding\": -0.96250981092453, \"dimension\": 4, \"position\": 28}, {\"embedding\": -0.9932565093040466, \"dimension\": 4, \"position\": 29}, {\"embedding\": -0.9991058707237244, \"dimension\": 4, \"position\": 30}, {\"embedding\": -0.9799113273620605, \"dimension\": 4, \"position\": 31}, {\"embedding\": -0.9361540079116821, \"dimension\": 4, \"position\": 32}, {\"embedding\": -0.8689308166503906, \"dimension\": 4, \"position\": 33}, {\"embedding\": -0.7799267172813416, \"dimension\": 4, \"position\": 34}, {\"embedding\": -0.6713724136352539, \"dimension\": 4, \"position\": 35}, {\"embedding\": -0.5459895133972168, \"dimension\": 4, \"position\": 36}, {\"embedding\": -0.40692076086997986, \"dimension\": 4, \"position\": 37}, {\"embedding\": -0.2576519548892975, \"dimension\": 4, \"position\": 38}, {\"embedding\": -0.10192479938268661, \"dimension\": 4, \"position\": 39}, {\"embedding\": 0.056357722729444504, \"dimension\": 4, \"position\": 40}, {\"embedding\": 0.21322709321975708, \"dimension\": 4, \"position\": 41}, {\"embedding\": 0.3647516369819641, \"dimension\": 4, \"position\": 42}, {\"embedding\": 0.5071332454681396, \"dimension\": 4, \"position\": 43}, {\"embedding\": 0.6368028521537781, \"dimension\": 4, \"position\": 44}, {\"embedding\": 0.7505101561546326, \"dimension\": 4, \"position\": 45}, {\"embedding\": 0.8454052805900574, \"dimension\": 4, \"position\": 46}, {\"embedding\": 0.9191088080406189, \"dimension\": 4, \"position\": 47}, {\"embedding\": 0.9697737693786621, \"dimension\": 4, \"position\": 48}, {\"embedding\": 0.9961300492286682, \"dimension\": 4, \"position\": 49}, {\"embedding\": 0.9975170493125916, \"dimension\": 4, \"position\": 50}, {\"embedding\": 0.9738998413085938, \"dimension\": 4, \"position\": 51}, {\"embedding\": 0.9258706569671631, \"dimension\": 4, \"position\": 52}, {\"embedding\": 0.8546332716941833, \"dimension\": 4, \"position\": 53}, {\"embedding\": 0.7619734406471252, \"dimension\": 4, \"position\": 54}, {\"embedding\": 0.6502137184143066, \"dimension\": 4, \"position\": 55}, {\"embedding\": 0.5221555233001709, \"dimension\": 4, \"position\": 56}, {\"embedding\": 0.38100889325141907, \"dimension\": 4, \"position\": 57}, {\"embedding\": 0.23031172156333923, \"dimension\": 4, \"position\": 58}, {\"embedding\": 0.07384055852890015, \"dimension\": 4, \"position\": 59}, {\"embedding\": -0.08448058366775513, \"dimension\": 4, \"position\": 60}, {\"embedding\": -0.2406841218471527, \"dimension\": 4, \"position\": 61}, {\"embedding\": -0.3908545970916748, \"dimension\": 4, \"position\": 62}, {\"embedding\": -0.5312277674674988, \"dimension\": 4, \"position\": 63}, {\"embedding\": -0.6582850813865662, \"dimension\": 4, \"position\": 64}, {\"embedding\": -0.768841564655304, \"dimension\": 4, \"position\": 65}, {\"embedding\": -0.8601260781288147, \"dimension\": 4, \"position\": 66}, {\"embedding\": -0.9298503994941711, \"dimension\": 4, \"position\": 67}, {\"embedding\": -0.9762668013572693, \"dimension\": 4, \"position\": 68}, {\"embedding\": -0.9982118010520935, \"dimension\": 4, \"position\": 69}, {\"embedding\": -0.9951352477073669, \"dimension\": 4, \"position\": 70}, {\"embedding\": -0.967114269733429, \"dimension\": 4, \"position\": 71}, {\"embedding\": -0.9148513078689575, \"dimension\": 4, \"position\": 72}, {\"embedding\": -0.839656412601471, \"dimension\": 4, \"position\": 73}, {\"embedding\": -0.7434144616127014, \"dimension\": 4, \"position\": 74}, {\"embedding\": -0.6285378336906433, \"dimension\": 4, \"position\": 75}, {\"embedding\": -0.4979061186313629, \"dimension\": 4, \"position\": 76}, {\"embedding\": -0.3547937273979187, \"dimension\": 4, \"position\": 77}, {\"embedding\": -0.20278796553611755, \"dimension\": 4, \"position\": 78}, {\"embedding\": -0.04569905996322632, \"dimension\": 4, \"position\": 79}, {\"embedding\": 0.11253630369901657, \"dimension\": 4, \"position\": 80}, {\"embedding\": 0.2679498493671417, \"dimension\": 4, \"position\": 81}, {\"embedding\": 0.4166468679904938, \"dimension\": 4, \"position\": 82}, {\"embedding\": 0.5549001097679138, \"dimension\": 4, \"position\": 83}, {\"embedding\": 0.6792440414428711, \"dimension\": 4, \"position\": 84}, {\"embedding\": 0.7865618467330933, \"dimension\": 4, \"position\": 85}, {\"embedding\": 0.8741634488105774, \"dimension\": 4, \"position\": 86}, {\"embedding\": 0.9398530125617981, \"dimension\": 4, \"position\": 87}, {\"embedding\": 0.9819839596748352, \"dimension\": 4, \"position\": 88}, {\"embedding\": 0.9995002150535583, \"dimension\": 4, \"position\": 89}, {\"embedding\": 0.9919626712799072, \"dimension\": 4, \"position\": 90}, {\"embedding\": 0.959559977054596, \"dimension\": 4, \"position\": 91}, {\"embedding\": 0.903104841709137, \"dimension\": 4, \"position\": 92}, {\"embedding\": 0.8240122199058533, \"dimension\": 4, \"position\": 93}, {\"embedding\": 0.7242646217346191, \"dimension\": 4, \"position\": 94}, {\"embedding\": 0.6063624024391174, \"dimension\": 4, \"position\": 95}, {\"embedding\": 0.4732609689235687, \"dimension\": 4, \"position\": 96}, {\"embedding\": 0.32829657196998596, \"dimension\": 4, \"position\": 97}, {\"embedding\": 0.17510302364826202, \"dimension\": 4, \"position\": 98}, {\"embedding\": 0.01752028614282608, \"dimension\": 4, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 5, \"position\": 0}, {\"embedding\": 0.9874668121337891, \"dimension\": 5, \"position\": 1}, {\"embedding\": 0.9501814842224121, \"dimension\": 5, \"position\": 2}, {\"embedding\": 0.8890786170959473, \"dimension\": 5, \"position\": 3}, {\"embedding\": 0.8056897521018982, \"dimension\": 5, \"position\": 4}, {\"embedding\": 0.7021052241325378, \"dimension\": 5, \"position\": 5}, {\"embedding\": 0.5809215903282166, \"dimension\": 5, \"position\": 6}, {\"embedding\": 0.44517630338668823, \"dimension\": 5, \"position\": 7}, {\"embedding\": 0.2982720732688904, \"dimension\": 5, \"position\": 8}, {\"embedding\": 0.14389123022556305, \"dimension\": 5, \"position\": 9}, {\"embedding\": -0.01409643329679966, \"dimension\": 5, \"position\": 10}, {\"embedding\": -0.1717306226491928, \"dimension\": 5, \"position\": 11}, {\"embedding\": -0.32506027817726135, \"dimension\": 5, \"position\": 12}, {\"embedding\": -0.47024187445640564, \"dimension\": 5, \"position\": 13}, {\"embedding\": -0.6036361455917358, \"dimension\": 5, \"position\": 14}, {\"embedding\": -0.7218996286392212, \"dimension\": 5, \"position\": 15}, {\"embedding\": -0.8220675587654114, \"dimension\": 5, \"position\": 16}, {\"embedding\": -0.9016293287277222, \"dimension\": 5, \"position\": 17}, {\"embedding\": -0.9585906267166138, \"dimension\": 5, \"position\": 18}, {\"embedding\": -0.9915235042572021, \"dimension\": 5, \"position\": 19}, {\"embedding\": -0.9996025562286377, \"dimension\": 5, \"position\": 20}, {\"embedding\": -0.9826252460479736, \"dimension\": 5, \"position\": 21}, {\"embedding\": -0.941017210483551, \"dimension\": 5, \"position\": 22}, {\"embedding\": -0.8758211731910706, \"dimension\": 5, \"position\": 23}, {\"embedding\": -0.788671612739563, \"dimension\": 5, \"position\": 24}, {\"embedding\": -0.6817529797554016, \"dimension\": 5, \"position\": 25}, {\"embedding\": -0.5577451586723328, \"dimension\": 5, \"position\": 26}, {\"embedding\": -0.4197568893432617, \"dimension\": 5, \"position\": 27}, {\"embedding\": -0.27124688029289246, \"dimension\": 5, \"position\": 28}, {\"embedding\": -0.11593768745660782, \"dimension\": 5, \"position\": 29}, {\"embedding\": 0.042278096079826355, \"dimension\": 5, \"position\": 30}, {\"embedding\": 0.19943365454673767, \"dimension\": 5, \"position\": 31}, {\"embedding\": 0.3515901565551758, \"dimension\": 5, \"position\": 32}, {\"embedding\": 0.4949335753917694, \"dimension\": 5, \"position\": 33}, {\"embedding\": 0.6258708238601685, \"dimension\": 5, \"position\": 34}, {\"embedding\": 0.7411201596260071, \"dimension\": 5, \"position\": 35}, {\"embedding\": 0.8377919793128967, \"dimension\": 5, \"position\": 36}, {\"embedding\": 0.9134634733200073, \"dimension\": 5, \"position\": 37}, {\"embedding\": 0.9662377834320068, \"dimension\": 5, \"position\": 38}, {\"embedding\": 0.994792103767395, \"dimension\": 5, \"position\": 39}, {\"embedding\": 0.9984106421470642, \"dimension\": 5, \"position\": 40}, {\"embedding\": 0.9770026803016663, \"dimension\": 5, \"position\": 41}, {\"embedding\": 0.931104838848114, \"dimension\": 5, \"position\": 42}, {\"embedding\": 0.8618676662445068, \"dimension\": 5, \"position\": 43}, {\"embedding\": 0.7710266709327698, \"dimension\": 5, \"position\": 44}, {\"embedding\": 0.6608588695526123, \"dimension\": 5, \"position\": 45}, {\"embedding\": 0.5341253876686096, \"dimension\": 5, \"position\": 46}, {\"embedding\": 0.3940037488937378, \"dimension\": 5, \"position\": 47}, {\"embedding\": 0.24400585889816284, \"dimension\": 5, \"position\": 48}, {\"embedding\": 0.08789165318012238, \"dimension\": 5, \"position\": 49}, {\"embedding\": -0.07042567431926727, \"dimension\": 5, \"position\": 50}, {\"embedding\": -0.2269781529903412, \"dimension\": 5, \"position\": 51}, {\"embedding\": -0.37784066796302795, \"dimension\": 5, \"position\": 52}, {\"embedding\": -0.5192320942878723, \"dimension\": 5, \"position\": 53}, {\"embedding\": -0.6476082801818848, \"dimension\": 5, \"position\": 54}, {\"embedding\": -0.7597513794898987, \"dimension\": 5, \"position\": 55}, {\"embedding\": -0.8528502583503723, \"dimension\": 5, \"position\": 56}, {\"embedding\": -0.9245713949203491, \"dimension\": 5, \"position\": 57}, {\"embedding\": -0.973116934299469, \"dimension\": 5, \"position\": 58}, {\"embedding\": -0.9972700476646423, \"dimension\": 5, \"position\": 59}, {\"embedding\": -0.9964250922203064, \"dimension\": 5, \"position\": 60}, {\"embedding\": -0.9706035256385803, \"dimension\": 5, \"position\": 61}, {\"embedding\": -0.9204524159431458, \"dimension\": 5, \"position\": 62}, {\"embedding\": -0.8472290635108948, \"dimension\": 5, \"position\": 63}, {\"embedding\": -0.7527687549591064, \"dimension\": 5, \"position\": 64}, {\"embedding\": -0.6394393444061279, \"dimension\": 5, \"position\": 65}, {\"embedding\": -0.5100815296173096, \"dimension\": 5, \"position\": 66}, {\"embedding\": -0.3679378628730774, \"dimension\": 5, \"position\": 67}, {\"embedding\": -0.2165713608264923, \"dimension\": 5, \"position\": 68}, {\"embedding\": -0.05977622792124748, \"dimension\": 5, \"position\": 69}, {\"embedding\": 0.09851823002099991, \"dimension\": 5, \"position\": 70}, {\"embedding\": 0.254342257976532, \"dimension\": 5, \"position\": 71}, {\"embedding\": 0.4037908613681793, \"dimension\": 5, \"position\": 72}, {\"embedding\": 0.543117880821228, \"dimension\": 5, \"position\": 73}, {\"embedding\": 0.6688309907913208, \"dimension\": 5, \"position\": 74}, {\"embedding\": 0.7777789831161499, \"dimension\": 5, \"position\": 75}, {\"embedding\": 0.8672309517860413, \"dimension\": 5, \"position\": 76}, {\"embedding\": 0.9349446296691895, \"dimension\": 5, \"position\": 77}, {\"embedding\": 0.9792226552963257, \"dimension\": 5, \"position\": 78}, {\"embedding\": 0.998955249786377, \"dimension\": 5, \"position\": 79}, {\"embedding\": 0.9936476349830627, \"dimension\": 5, \"position\": 80}, {\"embedding\": 0.9634328484535217, \"dimension\": 5, \"position\": 81}, {\"embedding\": 0.9090684056282043, \"dimension\": 5, \"position\": 82}, {\"embedding\": 0.8319169878959656, \"dimension\": 5, \"position\": 83}, {\"embedding\": 0.733912467956543, \"dimension\": 5, \"position\": 84}, {\"embedding\": 0.617511510848999, \"dimension\": 5, \"position\": 85}, {\"embedding\": 0.4856317937374115, \"dimension\": 5, \"position\": 86}, {\"embedding\": 0.3415791094303131, \"dimension\": 5, \"position\": 87}, {\"embedding\": 0.18896427750587463, \"dimension\": 5, \"position\": 88}, {\"embedding\": 0.0316128134727478, \"dimension\": 5, \"position\": 89}, {\"embedding\": -0.12653106451034546, \"dimension\": 5, \"position\": 90}, {\"embedding\": -0.28150418400764465, \"dimension\": 5, \"position\": 91}, {\"embedding\": -0.4294200837612152, \"dimension\": 5, \"position\": 92}, {\"embedding\": -0.5665720105171204, \"dimension\": 5, \"position\": 93}, {\"embedding\": -0.6895220875740051, \"dimension\": 5, \"position\": 94}, {\"embedding\": -0.7951884269714355, \"dimension\": 5, \"position\": 95}, {\"embedding\": -0.880922257900238, \"dimension\": 5, \"position\": 96}, {\"embedding\": -0.9445747137069702, \"dimension\": 5, \"position\": 97}, {\"embedding\": -0.9845501184463501, \"dimension\": 5, \"position\": 98}, {\"embedding\": -0.9998465180397034, \"dimension\": 5, \"position\": 99}, {\"embedding\": 0.0, \"dimension\": 6, \"position\": 0}, {\"embedding\": 0.06305388361215591, \"dimension\": 6, \"position\": 1}, {\"embedding\": 0.12585683166980743, \"dimension\": 6, \"position\": 2}, {\"embedding\": 0.18815888464450836, \"dimension\": 6, \"position\": 3}, {\"embedding\": 0.24971213936805725, \"dimension\": 6, \"position\": 4}, {\"embedding\": 0.31027159094810486, \"dimension\": 6, \"position\": 5}, {\"embedding\": 0.3695962131023407, \"dimension\": 6, \"position\": 6}, {\"embedding\": 0.4274499714374542, \"dimension\": 6, \"position\": 7}, {\"embedding\": 0.4836025834083557, \"dimension\": 6, \"position\": 8}, {\"embedding\": 0.5378305912017822, \"dimension\": 6, \"position\": 9}, {\"embedding\": 0.5899181365966797, \"dimension\": 6, \"position\": 10}, {\"embedding\": 0.6396579146385193, \"dimension\": 6, \"position\": 11}, {\"embedding\": 0.6868520379066467, \"dimension\": 6, \"position\": 12}, {\"embedding\": 0.7313126921653748, \"dimension\": 6, \"position\": 13}, {\"embedding\": 0.7728629112243652, \"dimension\": 6, \"position\": 14}, {\"embedding\": 0.8113372921943665, \"dimension\": 6, \"position\": 15}, {\"embedding\": 0.8465827703475952, \"dimension\": 6, \"position\": 16}, {\"embedding\": 0.8784590363502502, \"dimension\": 6, \"position\": 17}, {\"embedding\": 0.9068393111228943, \"dimension\": 6, \"position\": 18}, {\"embedding\": 0.9316105246543884, \"dimension\": 6, \"position\": 19}, {\"embedding\": 0.9526742100715637, \"dimension\": 6, \"position\": 20}, {\"embedding\": 0.9699464440345764, \"dimension\": 6, \"position\": 21}, {\"embedding\": 0.9833585619926453, \"dimension\": 6, \"position\": 22}, {\"embedding\": 0.9928570985794067, \"dimension\": 6, \"position\": 23}, {\"embedding\": 0.9984043836593628, \"dimension\": 6, \"position\": 24}, {\"embedding\": 0.999978244304657, \"dimension\": 6, \"position\": 25}, {\"embedding\": 0.9975724220275879, \"dimension\": 6, \"position\": 26}, {\"embedding\": 0.9911965131759644, \"dimension\": 6, \"position\": 27}, {\"embedding\": 0.9808759093284607, \"dimension\": 6, \"position\": 28}, {\"embedding\": 0.9666516780853271, \"dimension\": 6, \"position\": 29}, {\"embedding\": 0.9485803842544556, \"dimension\": 6, \"position\": 30}, {\"embedding\": 0.9267339110374451, \"dimension\": 6, \"position\": 31}, {\"embedding\": 0.9011994004249573, \"dimension\": 6, \"position\": 32}, {\"embedding\": 0.8720782399177551, \"dimension\": 6, \"position\": 33}, {\"embedding\": 0.8394865393638611, \"dimension\": 6, \"position\": 34}, {\"embedding\": 0.8035537600517273, \"dimension\": 6, \"position\": 35}, {\"embedding\": 0.7644230127334595, \"dimension\": 6, \"position\": 36}, {\"embedding\": 0.7222501039505005, \"dimension\": 6, \"position\": 37}, {\"embedding\": 0.6772029399871826, \"dimension\": 6, \"position\": 38}, {\"embedding\": 0.6294605135917664, \"dimension\": 6, \"position\": 39}, {\"embedding\": 0.57921302318573, \"dimension\": 6, \"position\": 40}, {\"embedding\": 0.5266605615615845, \"dimension\": 6, \"position\": 41}, {\"embedding\": 0.4720119535923004, \"dimension\": 6, \"position\": 42}, {\"embedding\": 0.41548484563827515, \"dimension\": 6, \"position\": 43}, {\"embedding\": 0.3573042154312134, \"dimension\": 6, \"position\": 44}, {\"embedding\": 0.29770180583000183, \"dimension\": 6, \"position\": 45}, {\"embedding\": 0.23691439628601074, \"dimension\": 6, \"position\": 46}, {\"embedding\": 0.17518411576747894, \"dimension\": 6, \"position\": 47}, {\"embedding\": 0.1127568930387497, \"dimension\": 6, \"position\": 48}, {\"embedding\": 0.04988069087266922, \"dimension\": 6, \"position\": 49}, {\"embedding\": -0.013194027356803417, \"dimension\": 6, \"position\": 50}, {\"embedding\": -0.07621623575687408, \"dimension\": 6, \"position\": 51}, {\"embedding\": -0.1389348804950714, \"dimension\": 6, \"position\": 52}, {\"embedding\": -0.20110084116458893, \"dimension\": 6, \"position\": 53}, {\"embedding\": -0.2624664604663849, \"dimension\": 6, \"position\": 54}, {\"embedding\": -0.3227875530719757, \"dimension\": 6, \"position\": 55}, {\"embedding\": -0.3818237781524658, \"dimension\": 6, \"position\": 56}, {\"embedding\": -0.4393406808376312, \"dimension\": 6, \"position\": 57}, {\"embedding\": -0.49510911107063293, \"dimension\": 6, \"position\": 58}, {\"embedding\": -0.5489069223403931, \"dimension\": 6, \"position\": 59}, {\"embedding\": -0.6005204319953918, \"dimension\": 6, \"position\": 60}, {\"embedding\": -0.6497439742088318, \"dimension\": 6, \"position\": 61}, {\"embedding\": -0.6963817477226257, \"dimension\": 6, \"position\": 62}, {\"embedding\": -0.7402478456497192, \"dimension\": 6, \"position\": 63}, {\"embedding\": -0.7811681628227234, \"dimension\": 6, \"position\": 64}, {\"embedding\": -0.8189795017242432, \"dimension\": 6, \"position\": 65}, {\"embedding\": -0.8535317182540894, \"dimension\": 6, \"position\": 66}, {\"embedding\": -0.8846868872642517, \"dimension\": 6, \"position\": 67}, {\"embedding\": -0.9123212099075317, \"dimension\": 6, \"position\": 68}, {\"embedding\": -0.936324954032898, \"dimension\": 6, \"position\": 69}, {\"embedding\": -0.956602156162262, \"dimension\": 6, \"position\": 70}, {\"embedding\": -0.9730724096298218, \"dimension\": 6, \"position\": 71}, {\"embedding\": -0.9856699705123901, \"dimension\": 6, \"position\": 72}, {\"embedding\": -0.9943448305130005, \"dimension\": 6, \"position\": 73}, {\"embedding\": -0.9990625381469727, \"dimension\": 6, \"position\": 74}, {\"embedding\": -0.9998041391372681, \"dimension\": 6, \"position\": 75}, {\"embedding\": -0.9965668320655823, \"dimension\": 6, \"position\": 76}, {\"embedding\": -0.9893633723258972, \"dimension\": 6, \"position\": 77}, {\"embedding\": -0.9782225489616394, \"dimension\": 6, \"position\": 78}, {\"embedding\": -0.963188648223877, \"dimension\": 6, \"position\": 79}, {\"embedding\": -0.9443213939666748, \"dimension\": 6, \"position\": 80}, {\"embedding\": -0.9216960668563843, \"dimension\": 6, \"position\": 81}, {\"embedding\": -0.8954026699066162, \"dimension\": 6, \"position\": 82}, {\"embedding\": -0.8655455708503723, \"dimension\": 6, \"position\": 83}, {\"embedding\": -0.8322440981864929, \"dimension\": 6, \"position\": 84}, {\"embedding\": -0.795630156993866, \"dimension\": 6, \"position\": 85}, {\"embedding\": -0.7558501362800598, \"dimension\": 6, \"position\": 86}, {\"embedding\": -0.7130619883537292, \"dimension\": 6, \"position\": 87}, {\"embedding\": -0.6674357056617737, \"dimension\": 6, \"position\": 88}, {\"embedding\": -0.6191535592079163, \"dimension\": 6, \"position\": 89}, {\"embedding\": -0.5684073567390442, \"dimension\": 6, \"position\": 90}, {\"embedding\": -0.5153986215591431, \"dimension\": 6, \"position\": 91}, {\"embedding\": -0.46033912897109985, \"dimension\": 6, \"position\": 92}, {\"embedding\": -0.40344759821891785, \"dimension\": 6, \"position\": 93}, {\"embedding\": -0.3449500501155853, \"dimension\": 6, \"position\": 94}, {\"embedding\": -0.28508007526397705, \"dimension\": 6, \"position\": 95}, {\"embedding\": -0.22407560050487518, \"dimension\": 6, \"position\": 96}, {\"embedding\": -0.1621788740158081, \"dimension\": 6, \"position\": 97}, {\"embedding\": -0.09963719546794891, \"dimension\": 6, \"position\": 98}, {\"embedding\": -0.03669850528240204, \"dimension\": 6, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 7, \"position\": 0}, {\"embedding\": 0.9980100989341736, \"dimension\": 7, \"position\": 1}, {\"embedding\": 0.9920483827590942, \"dimension\": 7, \"position\": 2}, {\"embedding\": 0.9821385741233826, \"dimension\": 7, \"position\": 3}, {\"embedding\": 0.9683201313018799, \"dimension\": 7, \"position\": 4}, {\"embedding\": 0.9506479501724243, \"dimension\": 7, \"position\": 5}, {\"embedding\": 0.9291924834251404, \"dimension\": 7, \"position\": 6}, {\"embedding\": 0.9040390253067017, \"dimension\": 7, \"position\": 7}, {\"embedding\": 0.8752877116203308, \"dimension\": 7, \"position\": 8}, {\"embedding\": 0.8430529236793518, \"dimension\": 7, \"position\": 9}, {\"embedding\": 0.8074630498886108, \"dimension\": 7, \"position\": 10}, {\"embedding\": 0.7686597108840942, \"dimension\": 7, \"position\": 11}, {\"embedding\": 0.7267972826957703, \"dimension\": 7, \"position\": 12}, {\"embedding\": 0.6820423603057861, \"dimension\": 7, \"position\": 13}, {\"embedding\": 0.6345730423927307, \"dimension\": 7, \"position\": 14}, {\"embedding\": 0.5845783352851868, \"dimension\": 7, \"position\": 15}, {\"embedding\": 0.532257080078125, \"dimension\": 7, \"position\": 16}, {\"embedding\": 0.47781768441200256, \"dimension\": 7, \"position\": 17}, {\"embedding\": 0.4214765727519989, \"dimension\": 7, \"position\": 18}, {\"embedding\": 0.36345821619033813, \"dimension\": 7, \"position\": 19}, {\"embedding\": 0.30399325489997864, \"dimension\": 7, \"position\": 20}, {\"embedding\": 0.243318572640419, \"dimension\": 7, \"position\": 21}, {\"embedding\": 0.18167544901371002, \"dimension\": 7, \"position\": 22}, {\"embedding\": 0.11930941045284271, \"dimension\": 7, \"position\": 23}, {\"embedding\": 0.056468550115823746, \"dimension\": 7, \"position\": 24}, {\"embedding\": -0.006597157102078199, \"dimension\": 7, \"position\": 25}, {\"embedding\": -0.06963648647069931, \"dimension\": 7, \"position\": 26}, {\"embedding\": -0.1323987990617752, \"dimension\": 7, \"position\": 27}, {\"embedding\": -0.1946340948343277, \"dimension\": 7, \"position\": 28}, {\"embedding\": -0.25609490275382996, \"dimension\": 7, \"position\": 29}, {\"embedding\": -0.31653639674186707, \"dimension\": 7, \"position\": 30}, {\"embedding\": -0.37571826577186584, \"dimension\": 7, \"position\": 31}, {\"embedding\": -0.43340474367141724, \"dimension\": 7, \"position\": 32}, {\"embedding\": -0.4893665015697479, \"dimension\": 7, \"position\": 33}, {\"embedding\": -0.5433804988861084, \"dimension\": 7, \"position\": 34}, {\"embedding\": -0.5952321887016296, \"dimension\": 7, \"position\": 35}, {\"embedding\": -0.6447150111198425, \"dimension\": 7, \"position\": 36}, {\"embedding\": -0.6916319727897644, \"dimension\": 7, \"position\": 37}, {\"embedding\": -0.7357962727546692, \"dimension\": 7, \"position\": 38}, {\"embedding\": -0.7770324349403381, \"dimension\": 7, \"position\": 39}, {\"embedding\": -0.8151761889457703, \"dimension\": 7, \"position\": 40}, {\"embedding\": -0.8500756621360779, \"dimension\": 7, \"position\": 41}, {\"embedding\": -0.8815921545028687, \"dimension\": 7, \"position\": 42}, {\"embedding\": -0.9096000790596008, \"dimension\": 7, \"position\": 43}, {\"embedding\": -0.933988094329834, \"dimension\": 7, \"position\": 44}, {\"embedding\": -0.9546589255332947, \"dimension\": 7, \"position\": 45}, {\"embedding\": -0.971530556678772, \"dimension\": 7, \"position\": 46}, {\"embedding\": -0.9845356941223145, \"dimension\": 7, \"position\": 47}, {\"embedding\": -0.9936226010322571, \"dimension\": 7, \"position\": 48}, {\"embedding\": -0.998755156993866, \"dimension\": 7, \"position\": 49}, {\"embedding\": -0.9999129772186279, \"dimension\": 7, \"position\": 50}, {\"embedding\": -0.9970912933349609, \"dimension\": 7, \"position\": 51}, {\"embedding\": -0.9903014898300171, \"dimension\": 7, \"position\": 52}, {\"embedding\": -0.9795705676078796, \"dimension\": 7, \"position\": 53}, {\"embedding\": -0.964941143989563, \"dimension\": 7, \"position\": 54}, {\"embedding\": -0.9464714527130127, \"dimension\": 7, \"position\": 55}, {\"embedding\": -0.9242351651191711, \"dimension\": 7, \"position\": 56}, {\"embedding\": -0.8983205556869507, \"dimension\": 7, \"position\": 57}, {\"embedding\": -0.8688308000564575, \"dimension\": 7, \"position\": 58}, {\"embedding\": -0.8358834981918335, \"dimension\": 7, \"position\": 59}, {\"embedding\": -0.7996094226837158, \"dimension\": 7, \"position\": 60}, {\"embedding\": -0.7601531147956848, \"dimension\": 7, \"position\": 61}, {\"embedding\": -0.7176715731620789, \"dimension\": 7, \"position\": 62}, {\"embedding\": -0.6723340749740601, \"dimension\": 7, \"position\": 63}, {\"embedding\": -0.6243206262588501, \"dimension\": 7, \"position\": 64}, {\"embedding\": -0.5738227963447571, \"dimension\": 7, \"position\": 65}, {\"embedding\": -0.5210408568382263, \"dimension\": 7, \"position\": 66}, {\"embedding\": -0.46618568897247314, \"dimension\": 7, \"position\": 67}, {\"embedding\": -0.4094752371311188, \"dimension\": 7, \"position\": 68}, {\"embedding\": -0.3511347472667694, \"dimension\": 7, \"position\": 69}, {\"embedding\": -0.2913972735404968, \"dimension\": 7, \"position\": 70}, {\"embedding\": -0.23049965500831604, \"dimension\": 7, \"position\": 71}, {\"embedding\": -0.1686851680278778, \"dimension\": 7, \"position\": 72}, {\"embedding\": -0.10619935393333435, \"dimension\": 7, \"position\": 73}, {\"embedding\": -0.04329042136669159, \"dimension\": 7, \"position\": 74}, {\"embedding\": 0.019790323451161385, \"dimension\": 7, \"position\": 75}, {\"embedding\": 0.08279230445623398, \"dimension\": 7, \"position\": 76}, {\"embedding\": 0.14546526968479156, \"dimension\": 7, \"position\": 77}, {\"embedding\": 0.20755885541439056, \"dimension\": 7, \"position\": 78}, {\"embedding\": 0.2688263952732086, \"dimension\": 7, \"position\": 79}, {\"embedding\": 0.3290245532989502, \"dimension\": 7, \"position\": 80}, {\"embedding\": 0.3879128098487854, \"dimension\": 7, \"position\": 81}, {\"embedding\": 0.4452572762966156, \"dimension\": 7, \"position\": 82}, {\"embedding\": 0.5008301138877869, \"dimension\": 7, \"position\": 83}, {\"embedding\": 0.5544094443321228, \"dimension\": 7, \"position\": 84}, {\"embedding\": 0.605782687664032, \"dimension\": 7, \"position\": 85}, {\"embedding\": 0.6547446846961975, \"dimension\": 7, \"position\": 86}, {\"embedding\": 0.7011010050773621, \"dimension\": 7, \"position\": 87}, {\"embedding\": 0.7446674108505249, \"dimension\": 7, \"position\": 88}, {\"embedding\": 0.7852699160575867, \"dimension\": 7, \"position\": 89}, {\"embedding\": 0.8227472901344299, \"dimension\": 7, \"position\": 90}, {\"embedding\": 0.856950581073761, \"dimension\": 7, \"position\": 91}, {\"embedding\": 0.8877431154251099, \"dimension\": 7, \"position\": 92}, {\"embedding\": 0.9150027632713318, \"dimension\": 7, \"position\": 93}, {\"embedding\": 0.9386210441589355, \"dimension\": 7, \"position\": 94}, {\"embedding\": 0.9585037231445312, \"dimension\": 7, \"position\": 95}, {\"embedding\": 0.9745717644691467, \"dimension\": 7, \"position\": 96}, {\"embedding\": 0.9867613911628723, \"dimension\": 7, \"position\": 97}, {\"embedding\": 0.9950238466262817, \"dimension\": 7, \"position\": 98}, {\"embedding\": 0.9993264079093933, \"dimension\": 7, \"position\": 99}]}}, {\"mode\": \"vega-lite\"});\n</script>","text/plain":"alt.Chart(...)"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"class PositionwiseFeedForward(nn.Module):\n    \"Implements FFN equation.\"\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.w_2(self.dropout(F.relu(self.w_1(x))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.267390Z","iopub.execute_input":"2025-03-06T05:06:08.267658Z","iopub.status.idle":"2025-03-06T05:06:08.272105Z","shell.execute_reply.started":"2025-03-06T05:06:08.267633Z","shell.execute_reply":"2025-03-06T05:06:08.271218Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"class Embeddings(nn.Module):\n    def __init__(self, d_model, vocab):\n        super(Embeddings, self).__init__()\n        self.lut = nn.Embedding(vocab, d_model)\n        self.d_model = d_model\n\n    def forward(self, x):\n        return self.lut(x) * math.sqrt(self.d_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.273580Z","iopub.execute_input":"2025-03-06T05:06:08.273785Z","iopub.status.idle":"2025-03-06T05:06:08.284972Z","shell.execute_reply.started":"2025-03-06T05:06:08.273767Z","shell.execute_reply":"2025-03-06T05:06:08.284175Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"def make_model(src_vocab, tgt_vocab, N=6, \n               d_model=512, d_ff=2048, h=8, dropout=0.1):\n    \"Helper: Construct a model from hyperparameters.\"\n    c = copy.deepcopy\n    attn = MultiHeadedAttention(h, d_model)\n    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n    position = PositionalEncoding(d_model, dropout)\n    model = EncoderDecoder(\n        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n                             c(ff), dropout), N),\n        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n        Generator(d_model, tgt_vocab))\n    \n    # This was important from their code. \n    \n    # Initialize parameters with Glorot / fan_avg.\n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform(p)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.285994Z","iopub.execute_input":"2025-03-06T05:06:08.286231Z","iopub.status.idle":"2025-03-06T05:06:08.294605Z","shell.execute_reply.started":"2025-03-06T05:06:08.286172Z","shell.execute_reply":"2025-03-06T05:06:08.293916Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# transformer = make_model(10,10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.295292Z","iopub.execute_input":"2025-03-06T05:06:08.295474Z","iopub.status.idle":"2025-03-06T05:06:08.309912Z","shell.execute_reply.started":"2025-03-06T05:06:08.295458Z","shell.execute_reply":"2025-03-06T05:06:08.309223Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"saved_vocab = torch.load('/kaggle/input/vocabs/vocabularies.pth')\nsrc_vocab = saved_vocab['src_vocab']\ntgt_vocab = saved_vocab['tgt_vocab']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.310622Z","iopub.execute_input":"2025-03-06T05:06:08.310838Z","iopub.status.idle":"2025-03-06T05:06:08.542243Z","shell.execute_reply.started":"2025-03-06T05:06:08.310820Z","shell.execute_reply":"2025-03-06T05:06:08.541548Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"tgt_vocab.get_itos()[10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.543899Z","iopub.execute_input":"2025-03-06T05:06:08.544112Z","iopub.status.idle":"2025-03-06T05:06:08.549448Z","shell.execute_reply.started":"2025-03-06T05:06:08.544093Z","shell.execute_reply":"2025-03-06T05:06:08.548739Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"','"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"# from torchtext.datasets import AG_NEWS\n\n# # Download data\n# train_iter = AG_NEWS(split='train')\n# test_iter = AG_NEWS(split='test')\n\n\n# for label, text in train_iter:\n#     print(\"Label:\", label)  # Category number\n#     print(\"Text:\", text)    # News text\n#     break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.550730Z","iopub.execute_input":"2025-03-06T05:06:08.550930Z","iopub.status.idle":"2025-03-06T05:06:08.562269Z","shell.execute_reply.started":"2025-03-06T05:06:08.550912Z","shell.execute_reply":"2025-03-06T05:06:08.561479Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load German-English dataset\ndataset = load_dataset(\"helsinki-nlp/tatoeba_mt\", language_pair=\"deu-eng\",trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:08.563053Z","iopub.execute_input":"2025-03-06T05:06:08.563339Z","iopub.status.idle":"2025-03-06T05:06:25.516585Z","shell.execute_reply.started":"2025-03-06T05:06:08.563309Z","shell.execute_reply":"2025-03-06T05:06:25.515941Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616ed86195c8426baa3df20463be6e4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tatoeba_mt.py:   0%|          | 0.00/15.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f25c592dac704848b3d7eb7901fe272b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07b07de9a9f644258d8bbf6968bc111e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tatoeba-test.deu-eng.tsv:   0%|          | 0.00/1.60M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a43e05688d0641ac97862e7cf184409c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tatoeba-dev.deu-eng.tsv:   0%|          | 0.00/25.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b03b8638d984ebdb1edfb08c9f1ec7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d51a094fc5c743a3937fccd6015c19bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fe43eec17d940c3ba49393aa32232c0"}},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:25.517343Z","iopub.execute_input":"2025-03-06T05:06:25.517553Z","iopub.status.idle":"2025-03-06T05:06:25.522121Z","shell.execute_reply.started":"2025-03-06T05:06:25.517527Z","shell.execute_reply":"2025-03-06T05:06:25.521430Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['sourceLang', 'targetlang', 'sourceString', 'targetString'],\n        num_rows: 17564\n    })\n    validation: Dataset({\n        features: ['sourceLang', 'targetlang', 'sourceString', 'targetString'],\n        num_rows: 289748\n    })\n})"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"# Check dataset structure\nprint(dataset)\n\n# Look at a sample\nfor sample in dataset['test']:\n    print(\"Source Language:\", sample['sourceLang'])\n    print(\"Target Language:\", sample['targetlang'])\n    print(\"Source String:\", sample['sourceString'])\n    print(\"Target String:\", sample['targetString'])\n    break\n\n# Set up tokenizers\nimport spacy\nde_tokenizer = spacy.load('de_core_news_sm')\nen_tokenizer = spacy.load('en_core_web_sm')\n\n# Test tokenization\nsource_text = sample['sourceString']\ntarget_text = sample['targetString']\n\nprint(\"\\nTokenized Source:\", [token.text for token in de_tokenizer(source_text)])\nprint(\"Tokenized Target:\", [token.text for token in en_tokenizer(target_text)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:25.522817Z","iopub.execute_input":"2025-03-06T05:06:25.523008Z","iopub.status.idle":"2025-03-06T05:06:28.271198Z","shell.execute_reply.started":"2025-03-06T05:06:25.522991Z","shell.execute_reply":"2025-03-06T05:06:28.270374Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    test: Dataset({\n        features: ['sourceLang', 'targetlang', 'sourceString', 'targetString'],\n        num_rows: 17564\n    })\n    validation: Dataset({\n        features: ['sourceLang', 'targetlang', 'sourceString', 'targetString'],\n        num_rows: 289748\n    })\n})\nSource Language: deu\nTarget Language: eng\nSource String: 1960 wurden die KriegsschÃ¤den beseitigt, und das Schloss wurde zu einem Hotel umgebaut.\nTarget String: In 1960, the collateral had been removed and the castle was refurbished into a hotel.\n\nTokenized Source: ['1960', 'wurden', 'die', 'KriegsschÃ¤den', 'beseitigt', ',', 'und', 'das', 'Schloss', 'wurde', 'zu', 'einem', 'Hotel', 'umgebaut', '.']\nTokenized Target: ['In', '1960', ',', 'the', 'collateral', 'had', 'been', 'removed', 'and', 'the', 'castle', 'was', 'refurbished', 'into', 'a', 'hotel', '.']\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass VocabDataset(Dataset):\n    def __init__(self, dataset, src_tokenizer, tgt_tokenizer):\n        self.dataset = dataset\n        self.src_tokenizer = src_tokenizer\n        self.tgt_tokenizer = tgt_tokenizer\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):\n        # Get sample\n        sample = self.dataset[idx]\n        \n        # Get source and target texts\n        src_text = sample['sourceString']\n        tgt_text = sample['targetString']\n        \n        # Tokenize\n        src_tokens = [token.text for token in self.src_tokenizer(src_text)]\n        tgt_tokens = [token.text for token in self.tgt_tokenizer(tgt_text)]\n\n\n        \n        return {\n            'src': src_tokens,\n            'tgt': tgt_tokens\n        }\nsubset_size = 50000\ntrain_subset = dataset['validation'].select(range(5000))\n\n\n\n# Create datasets\nvocab_dataset  = VocabDataset(\n    train_subset,  # Using validation as train for now\n    de_tokenizer,\n    en_tokenizer\n)\n\n\n\n# Test it\nsample = vocab_dataset[0]\nprint(\"Source tokens:\", sample['src'])\nprint(\"Target tokens:\", sample['tgt'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:28.272005Z","iopub.execute_input":"2025-03-06T05:06:28.272335Z","iopub.status.idle":"2025-03-06T05:06:28.302295Z","shell.execute_reply.started":"2025-03-06T05:06:28.272311Z","shell.execute_reply":"2025-03-06T05:06:28.301553Z"}},"outputs":[{"name":"stdout","text":"Source tokens: ['10', 'Jahre', 'sind', 'eine', 'lange', 'Zeit', 'zum', 'Warten', '.']\nTarget tokens: ['Ten', 'years', 'is', 'a', 'long', 'time', 'to', 'wait', '.']\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"len(vocab_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:28.303024Z","iopub.execute_input":"2025-03-06T05:06:28.303249Z","iopub.status.idle":"2025-03-06T05:06:28.308070Z","shell.execute_reply.started":"2025-03-06T05:06:28.303229Z","shell.execute_reply":"2025-03-06T05:06:28.307214Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"5000"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"# from torchtext.vocab import build_vocab_from_iterator\n# from tqdm import tqdm\n# # Token yield functions\n# def yield_tokens_src(dataset):\n#     for i in tqdm(range(len(dataset)), desc=\"Building source vocab\"):\n#         yield dataset[i]['src']\n\n# def yield_tokens_tgt(dataset):\n#     for i in tqdm(range(len(dataset)),desc = \"Building target vocab\"):\n#         yield dataset[i]['tgt']\n\n# # Special tokens\n# special_tokens = ['<pad>', '<sos>', '<eos>', '<unk>']\n\n# # Build vocabularies\n# src_vocab = build_vocab_from_iterator(\n#     yield_tokens_src(vocab_dataset),\n#     min_freq=2,\n#     specials=special_tokens,\n#     special_first=True\n# )\n\n# tgt_vocab = build_vocab_from_iterator(\n#     yield_tokens_tgt(vocab_dataset),\n#     min_freq=2,\n#     specials=special_tokens,\n#     special_first=True\n# )\n\n# # Set UNK index\n# src_vocab.set_default_index(src_vocab['<unk>'])\n# tgt_vocab.set_default_index(tgt_vocab['<unk>'])\n\n# # Test vocabularies\n# print(\"Source vocab size:\", len(src_vocab))\n# print(\"Target vocab size:\", len(tgt_vocab))\n\n# # Test conversion\n# sample = vocab_dataset[0]\n# print(\"\\nSource tokens:\", sample['src'])\n# print(\"Source indices:\", [src_vocab[token] for token in sample['src']])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:28.308991Z","iopub.execute_input":"2025-03-06T05:06:28.309296Z","iopub.status.idle":"2025-03-06T05:06:28.324173Z","shell.execute_reply.started":"2025-03-06T05:06:28.309267Z","shell.execute_reply":"2025-03-06T05:06:28.323374Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# # Save vocabularies\n# import torch\n# torch.save({\n#     'src_vocab': src_vocab,\n#     'tgt_vocab': tgt_vocab\n# }, 'vocabularies.pth')\n\n# Load vocabularies later\nsaved_vocab = torch.load('/kaggle/input/vocabs/vocabularies.pth')\nsrc_vocab = saved_vocab['src_vocab']\ntgt_vocab = saved_vocab['tgt_vocab']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:28.324921Z","iopub.execute_input":"2025-03-06T05:06:28.325217Z","iopub.status.idle":"2025-03-06T05:06:28.570144Z","shell.execute_reply.started":"2025-03-06T05:06:28.325170Z","shell.execute_reply":"2025-03-06T05:06:28.569444Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"saved_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:28.570861Z","iopub.execute_input":"2025-03-06T05:06:28.571097Z","iopub.status.idle":"2025-03-06T05:06:28.576035Z","shell.execute_reply.started":"2025-03-06T05:06:28.571077Z","shell.execute_reply":"2025-03-06T05:06:28.575216Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"{'src_vocab': Vocab(), 'tgt_vocab': Vocab()}"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"# [tgt_vocab[token] for token in sample['tgt']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:28.579474Z","iopub.execute_input":"2025-03-06T05:06:28.579709Z","iopub.status.idle":"2025-03-06T05:06:28.591128Z","shell.execute_reply.started":"2025-03-06T05:06:28.579688Z","shell.execute_reply":"2025-03-06T05:06:28.590518Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom tqdm import tqdm\nclass TranslationDataset(Dataset):\n    def __init__(self, dataset, src_tokenizer, tgt_tokenizer,src_vocab, tgt_vocab,max_len=512):\n        self.dataset = dataset\n        self.src_tokenizer = src_tokenizer\n        self.tgt_tokenizer = tgt_tokenizer\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n        self.max_len=max_len\n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):\n        # Get sample\n        sample = self.dataset[idx]\n        \n        # Get source and target texts\n        src_text = sample['sourceString']\n        tgt_text = sample['targetString']\n        \n        # Tokenize\n        src_indices = [self.src_vocab[token.text] for token in self.src_tokenizer(src_text)]\n        tgt_indices = [self.tgt_vocab[token.text] for token in self.tgt_tokenizer(tgt_text)]\n        \n\n        src_indices = src_indices[:self.max_len-1] + [self.src_vocab['<eos>']]\n        tgt_indices = [self.tgt_vocab['<sos>']] + tgt_indices[:self.max_len-2] + [self.tgt_vocab['<eos>']]\n\n        src_indices =src_indices +(self.max_len-len(src_indices)) * [self.src_vocab['<pad>']]\n        tgt_indices = tgt_indices +(self.max_len-len(tgt_indices)) * [self.tgt_vocab['<pad>']]\n        return {\n            'src': torch.tensor(src_indices),\n            'tgt': torch.tensor(tgt_indices)\n        }\n\n# Create datasets\ntrain_dataset = TranslationDataset(\n    dataset['validation'],  # Using validation as train for now\n    de_tokenizer,\n    en_tokenizer,\n    src_vocab,\n    tgt_vocab\n)\n\n\n# Test it\nsample = train_dataset[0]\nprint(\"Source tokens:\", sample['src'])\nprint(\"Target tokens:\", sample['tgt'])\n\n# Convert back to tokens to verify\nprint(\"\\nSource tokens:\", [src_vocab.get_itos()[idx.item()] for idx in sample['src']])\nprint(\"Target tokens:\", [tgt_vocab.get_itos()[idx.item()] for idx in sample['tgt']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:28.592376Z","iopub.execute_input":"2025-03-06T05:06:28.592567Z","iopub.status.idle":"2025-03-06T05:06:29.489113Z","shell.execute_reply.started":"2025-03-06T05:06:28.592551Z","shell.execute_reply":"2025-03-06T05:06:29.488413Z"}},"outputs":[{"name":"stdout","text":"Source tokens: tensor([1316,  210,   32,   25,  312,  125,   84, 6507,    4,    2,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0])\nTarget tokens: tensor([   1, 8338,  159,    7,    9,  151,   67,    8,  560,    4,    2,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0])\n\nSource tokens: ['10', 'Jahre', 'sind', 'eine', 'lange', 'Zeit', 'zum', 'Warten', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\nTarget tokens: ['<sos>', 'Ten', 'years', 'is', 'a', 'long', 'time', 'to', 'wait', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=24,\n    shuffle=True\n)\n\n# Test the loader\n# for batch in train_loader:\n#     print(\"Source shape:\", batch['src'].shape)  # Should be [batch_size, max_len]\n#     print(\"Target shape:\", batch['tgt'].shape)\n#     break\n\n# for batch in train_loader:\n#     src_tokens=[[src_vocab.get_itos()[idx]for idx in seq]for seq in batch['src'][:2]]\n#     print(\"\\nFirst two source sequences:\")\n#     print(src_tokens)\n#     tgt_tokens=[[tgt_vocab.get_itos()[idx]for idx in seq]for seq in batch['tgt'][:2]]\n#     print(\"\\nFirst two source sequences:\")\n#     print(tgt_tokens)\n#     braek\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.489839Z","iopub.execute_input":"2025-03-06T05:06:29.490047Z","iopub.status.idle":"2025-03-06T05:06:29.493941Z","shell.execute_reply.started":"2025-03-06T05:06:29.490029Z","shell.execute_reply":"2025-03-06T05:06:29.493240Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"# # 1. Move model to CPU first\n# model = model.cpu()\n\n# # 2. Delete the model\n# del model\n\n# # 3. Clear GPU cache\n# torch.cuda.empty_cache()\n\n# # 4. Additional cleanup\n# import gc\n# gc.collect()\n\n# # Check GPU memory\n# import GPUtil\n# GPUtil.showUtilization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.494712Z","iopub.execute_input":"2025-03-06T05:06:29.494986Z","iopub.status.idle":"2025-03-06T05:06:29.511063Z","shell.execute_reply.started":"2025-03-06T05:06:29.494954Z","shell.execute_reply":"2025-03-06T05:06:29.510451Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"# import GPUtil\n# GPUtil.showUtilization()\n\n# # Or more detailed info\n# print(torch.cuda.memory_summary())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.511848Z","iopub.execute_input":"2025-03-06T05:06:29.512144Z","iopub.status.idle":"2025-03-06T05:06:29.522495Z","shell.execute_reply.started":"2025-03-06T05:06:29.512115Z","shell.execute_reply":"2025-03-06T05:06:29.521694Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"# # At the end of your training\n# wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.523320Z","iopub.execute_input":"2025-03-06T05:06:29.523529Z","iopub.status.idle":"2025-03-06T05:06:29.536308Z","shell.execute_reply.started":"2025-03-06T05:06:29.523510Z","shell.execute_reply":"2025-03-06T05:06:29.535543Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.537176Z","iopub.execute_input":"2025-03-06T05:06:29.537510Z","iopub.status.idle":"2025-03-06T05:06:29.550122Z","shell.execute_reply.started":"2025-03-06T05:06:29.537480Z","shell.execute_reply":"2025-03-06T05:06:29.549273Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"d_model=256\nn_heads=8\nN=6\nmodel = make_model(\n    src_vocab=len(src_vocab),\n    tgt_vocab=len(tgt_vocab),\n    N=N,\n    d_model=d_model,  \n    d_ff=1024,    \n    h=n_heads,\n    dropout=0.1\n)\n\n# 4. Move model to GPU and set up training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\nn_epochs = 5   \nlearning_rate = 0.0001  \n\n# 3. Loss and Optimizer\ncriterion = nn.NLLLoss(ignore_index=tgt_vocab['<pad>'])\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-9)\n\n# 4. Learning Rate Scheduler (optional but helpful)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.1, patience=2, verbose=True\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.550828Z","iopub.execute_input":"2025-03-06T05:06:29.551110Z","iopub.status.idle":"2025-03-06T05:06:29.828114Z","shell.execute_reply.started":"2025-03-06T05:06:29.551083Z","shell.execute_reply":"2025-03-06T05:06:29.827359Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.829320Z","iopub.execute_input":"2025-03-06T05:06:29.829617Z","iopub.status.idle":"2025-03-06T05:06:29.833120Z","shell.execute_reply.started":"2025-03-06T05:06:29.829582Z","shell.execute_reply":"2025-03-06T05:06:29.832353Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\n\nwandb.login(key=secret_value_0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:29.834002Z","iopub.execute_input":"2025-03-06T05:06:29.834327Z","iopub.status.idle":"2025-03-06T05:06:30.005686Z","shell.execute_reply.started":"2025-03-06T05:06:29.834304Z","shell.execute_reply":"2025-03-06T05:06:30.004982Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"\n\nbatch_size=28\naccumulation_steps=4\nimport wandb\n# wandb.login(key='5160da7d6632bf129ee82d18c94a11388dc6bcb6')\nwandb.init(\n    project=\"transformer-translation(subset_train)\",\n    config={\n        \"batch_size\": batch_size,\n        \"accumulation_steps\": accumulation_steps,\n        \"learning_rate\": learning_rate,\n        \"d_model\": d_model,\n        \"n_heads\": n_heads,\n        \"n_layers\": N,\n    }\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:30.006503Z","iopub.execute_input":"2025-03-06T05:06:30.006758Z","iopub.status.idle":"2025-03-06T05:06:30.022518Z","shell.execute_reply.started":"2025-03-06T05:06:30.006737Z","shell.execute_reply":"2025-03-06T05:06:30.021782Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/basem-yasser/transformer-translation%28subset_train%29/runs/7kz9s5o0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7e7ec0b227a0>"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\naccumulation_steps = 4\nscaler = GradScaler()\ndef train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    optimizer.zero_grad()\n    global_step = 0\n    \n    for i, batch in enumerate(tqdm(dataloader)):\n        try:\n            # Move to device\n            src = batch['src'].to(device)\n            tgt = batch['tgt'].to(device)\n            \n            # Create masks\n            src_mask = (src != src_vocab['<pad>']).unsqueeze(-2)\n            tgt_input = tgt[:, :-1]\n            tgt_output = tgt[:, 1:]\n            \n            tgt_pad_mask = (tgt_input != tgt_vocab['<pad>']).unsqueeze(-2)\n            tgt_sub_mask = subsequent_mask(tgt_input.size(-1)).to(device)\n            tgt_mask = tgt_pad_mask & tgt_sub_mask\n            \n            # Forward pass with mixed precision\n            with autocast():\n                output = model(src, tgt_input, src_mask, tgt_mask)\n                loss = criterion(\n                    output.contiguous().view(-1, output.size(-1)),\n                    tgt_output.contiguous().view(-1)\n                )\n                loss = loss / accumulation_steps\n\n            # Log to wandb\n            wandb.log({\n                \"batch_loss\": loss.item() * accumulation_steps,\n                \"global_step\": global_step\n            })\n            global_step += 1\n            \n            # Backward pass with scaled gradients\n            scaler.scale(loss).backward()\n            \n            # Update weights every accumulation_steps\n            if (i + 1) % accumulation_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n            \n            total_loss += loss.item() * accumulation_steps\n            \n        except RuntimeError as e:\n            print(\"Error in batch!\")\n            print(f\"Source shape: {src.shape}\")\n            print(f\"Target input shape: {tgt_input.shape}\")\n            print(f\"Target output shape: {tgt_output.shape}\")\n            print(f\"Output shape: {output.shape}\")\n            raise e\n    \n    # Handle remaining gradients\n    if (i + 1) % accumulation_steps != 0:\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n            \n    return total_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:30.023484Z","iopub.execute_input":"2025-03-06T05:06:30.023757Z","iopub.status.idle":"2025-03-06T05:06:30.031952Z","shell.execute_reply.started":"2025-03-06T05:06:30.023737Z","shell.execute_reply":"2025-03-06T05:06:30.031065Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"# batch_size = 24 # or 16 if 32 is too much\n# train_loader = DataLoader(\n#     train_dataset,\n#     batch_size=batch_size,\n#     shuffle=True\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:30.032590Z","iopub.execute_input":"2025-03-06T05:06:30.032869Z","iopub.status.idle":"2025-03-06T05:06:30.047976Z","shell.execute_reply.started":"2025-03-06T05:06:30.032839Z","shell.execute_reply":"2025-03-06T05:06:30.047083Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"# best_loss = float('inf')\n# for epoch in range(n_epochs):\n#     loss = train_epoch(model, train_loader, optimizer, criterion, device)\n    \n#     # Log epoch metrics\n#     wandb.log({\n#         \"epoch\": epoch,\n#         \"epoch_loss\": loss,\n#     })\n    \n#     # Save checkpoint\n#     if loss < best_loss:\n#         best_loss = loss\n#         torch.save({\n#             'epoch': epoch,\n#             'model_state_dict': model.state_dict(),\n#             'optimizer_state_dict': optimizer.state_dict(),\n#             'loss': loss,\n#         }, 'best_model.pt')\n#         # Save to wandb\n#         wandb.save('best_model.pt')\n    \n#     print(f'Epoch: {epoch+1}, Loss: {loss:.4f}')\n\n# # Finish wandb run\n# wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:30.048883Z","iopub.execute_input":"2025-03-06T05:06:30.049111Z","iopub.status.idle":"2025-03-06T05:06:30.062056Z","shell.execute_reply.started":"2025-03-06T05:06:30.049092Z","shell.execute_reply":"2025-03-06T05:06:30.061322Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/input/lastcheckpoint/best_model.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:30.062760Z","iopub.execute_input":"2025-03-06T05:06:30.063040Z","iopub.status.idle":"2025-03-06T05:06:30.360837Z","shell.execute_reply.started":"2025-03-06T05:06:30.063013Z","shell.execute_reply":"2025-03-06T05:06:30.360124Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"checkpoint['loss']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:30.362161Z","iopub.execute_input":"2025-03-06T05:06:30.362484Z","iopub.status.idle":"2025-03-06T05:06:30.367343Z","shell.execute_reply.started":"2025-03-06T05:06:30.362452Z","shell.execute_reply":"2025-03-06T05:06:30.366620Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"2.2627141343519375"},"metadata":{}}],"execution_count":104},{"cell_type":"markdown","source":"continue train on subset of the data","metadata":{}},{"cell_type":"code","source":"\ntrain_dataset_subset = TranslationDataset(\n    train_subset, \n    de_tokenizer, \n    en_tokenizer, \n    src_vocab, \n    tgt_vocab\n)\n\n# New dataloader\ntrain_loader_subset = DataLoader(\n    train_dataset_subset,\n    batch_size=28,\n    shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:43.343461Z","iopub.execute_input":"2025-03-06T05:06:43.343764Z","iopub.status.idle":"2025-03-06T05:06:43.348169Z","shell.execute_reply.started":"2025-03-06T05:06:43.343742Z","shell.execute_reply":"2025-03-06T05:06:43.347259Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"\nstart_epoch = checkpoint['epoch']\nstart_epoch \ncheckpoint['loss']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:43.767074Z","iopub.execute_input":"2025-03-06T05:06:43.767392Z","iopub.status.idle":"2025-03-06T05:06:43.772934Z","shell.execute_reply.started":"2025-03-06T05:06:43.767368Z","shell.execute_reply":"2025-03-06T05:06:43.772173Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"2.2627141343519375"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/input/lastcheckpoint/best_model.pt')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nstart_epoch = checkpoint['epoch']\n\nbest_loss=checkpoint['loss']\nbest_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:44.887517Z","iopub.execute_input":"2025-03-06T05:06:44.887821Z","iopub.status.idle":"2025-03-06T05:06:45.292500Z","shell.execute_reply.started":"2025-03-06T05:06:44.887800Z","shell.execute_reply":"2025-03-06T05:06:45.291631Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"2.2627141343519375"},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"\n# # Continue training\n# for epoch in range(start_epoch+1, n_epochs):\n#     loss = train_epoch(model, train_loader_subset, optimizer, criterion, device)\n    \n#     wandb.log({\n#         \"epoch\": epoch,\n#         \"epoch_loss\": loss,\n#     })\n#     torch.save({\n#         'epoch': epoch,\n#         'model_state_dict': model.state_dict(),\n#         'optimizer_state_dict': optimizer.state_dict(),\n#         'loss': loss,\n#     }, f'checkpoint_epoch_{epoch+1}.pt')\n#     wandb.save(f'checkpoint_epoch_{epoch+1}.pt')\n#     # Save checkpoint\n#     if loss < best_loss:\n#         best_loss = loss\n#         torch.save({\n#             'epoch': epoch,\n#             'model_state_dict': model.state_dict(),\n#             'optimizer_state_dict': optimizer.state_dict(),\n#             'loss': loss,\n#         }, 'best_model.pt')\n#         # Save to wandb\n#         wandb.save('best_model.pt')\n    \n#     print(f'Epoch: {epoch+1}, Loss: {loss:.4f}')\n\n# # Finish wandb run\n# wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:21:28.307366Z","iopub.execute_input":"2025-03-05T19:21:28.307675Z","iopub.status.idle":"2025-03-05T19:21:28.311314Z","shell.execute_reply.started":"2025-03-05T19:21:28.307653Z","shell.execute_reply":"2025-03-05T19:21:28.310376Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"\n# !mkdir -p /kaggle/working/transformer_dataset\n\n\n# !cp '/kaggle/input/modelcheckpoint2/best_model(1 epoch).pt' '/kaggle/working/transformer_dataset/best_model.pt'\n# !cp /kaggle/input/vocabs/vocabularies.pth /kaggle/working/transformer_dataset/\n# !cp /kaggle/working/best_model.pt /kaggle/working/transformer_dataset/\n\n# metadata = {\n#     \"title\": \"transformer-checkpoints\",\n#     \"id\": \"basem/transformer-checkpoints\",  \n#     \"licenses\": [{\"name\": \"CC0-1.0\"}]\n# }\n\n# import json\n# with open('/kaggle/working/transformer_dataset/dataset-metadata.json', 'w') as f:\n#     json.dump(metadata, f)\n\n# # 4. Create dataset\n# from kaggle.api.kaggle_api_extended import KaggleApi\n# api = KaggleApi()\n# api.authenticate()\n# api.dataset_create_version(\n#     folder='/kaggle/working/transformer_dataset',\n#     version_notes='New checkpoint'\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T19:21:50.318903Z","iopub.execute_input":"2025-03-05T19:21:50.319235Z","iopub.status.idle":"2025-03-05T19:21:50.324563Z","shell.execute_reply.started":"2025-03-05T19:21:50.319211Z","shell.execute_reply":"2025-03-05T19:21:50.323385Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-70b8f9e5d692>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"],"ename":"SyntaxError","evalue":"unmatched ')' (<ipython-input-59-70b8f9e5d692>, line 25)","output_type":"error"}],"execution_count":59},{"cell_type":"code","source":"test_subset = dataset['test'].select(range(7000))\ntest_subset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:49.297222Z","iopub.execute_input":"2025-03-06T05:06:49.297524Z","iopub.status.idle":"2025-03-06T05:06:49.305102Z","shell.execute_reply.started":"2025-03-06T05:06:49.297500Z","shell.execute_reply":"2025-03-06T05:06:49.304272Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sourceLang', 'targetlang', 'sourceString', 'targetString'],\n    num_rows: 7000\n})"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"test_dataset = TranslationDataset(\n    train_subset,\n    de_tokenizer,\n    en_tokenizer,\n    src_vocab,\n    tgt_vocab\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=28,\n    shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:49.642083Z","iopub.execute_input":"2025-03-06T05:06:49.642410Z","iopub.status.idle":"2025-03-06T05:06:49.646403Z","shell.execute_reply.started":"2025-03-06T05:06:49.642383Z","shell.execute_reply":"2025-03-06T05:06:49.645569Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"len(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:50.907158Z","iopub.execute_input":"2025-03-06T05:06:50.907490Z","iopub.status.idle":"2025-03-06T05:06:50.912455Z","shell.execute_reply.started":"2025-03-06T05:06:50.907464Z","shell.execute_reply":"2025-03-06T05:06:50.911637Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"5000"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"tgt_vocab['<pad>']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:06:51.442941Z","iopub.execute_input":"2025-03-06T05:06:51.443317Z","iopub.status.idle":"2025-03-06T05:06:51.449028Z","shell.execute_reply.started":"2025-03-06T05:06:51.443286Z","shell.execute_reply":"2025-03-06T05:06:51.448274Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"from torchtext.data.metrics import bleu_score\n\ndef calculate_metrics(predictions, targets, pad_idx):\n    # Accuracy\n\n    \n    # # Convert tensors to lists of tokens for BLEU\n    # pred_tokens = []\n    # target_tokens = []\n    \n    # for pred, tgt in zip(predictions, targets):\n    #     # Remove padding and convert to list\n    #     pred_clean = [str(p.item()) for p in pred if p.item() != pad_idx]\n    #     tgt_clean = [str(t.item()) for t in tgt if t.item() != pad_idx]\n        \n    #     pred_tokens.append(pred_clean)\n    #     target_tokens.append([tgt_clean])  # BLEU expects list of references\n    \n    # Calculate BLEU score\n    bleu = bleu_score(predictions, targets)\n    \n    return  bleu\n\n# Using in evaluation:\nmodel.eval()\nwith torch.no_grad():\n    max_len=512\n    num_batches = len(test_loader)\n    all_prediction=[]\n    all_references=[]\n    \n    for batch in tqdm(test_loader):\n        src = batch['src'].to(device)\n        tgt = batch['tgt'].to(device)\n        for b in range(src.size(0)): #b = index in batch\n            single_src = src[b : b+1] # shape [1, src_len]\n            \n            single_src_mask = (single_src != src_vocab['<pad>']).unsqueeze(-2)\n             \n            \n            \n            \n            # tgt_pad_mask = (tgt_input != tgt_vocab['<pad>']).unsqueeze(-2)\n            # tgt_sub_mask = subsequent_mask(tgt_input.size(-1)).to(device)\n            # tgt_mask = tgt_pad_mask & tgt_sub_mask\n            \n            memory = model.encode(single_src, single_src_mask)\n            ys = torch.full((1, 1), tgt_vocab['<sos>'],\n                          dtype=torch.long, device=device)\n            \n            for i in range(max_len):\n                tgt_mask = subsequent_mask(ys.size(1)).to(device)\n                out = model.decode(memory, single_src_mask, ys, tgt_mask)\n                prob = model.generator(out[:, -1])\n                _, next_word = torch.max(prob, dim=1)\n                ys = torch.cat([ys, next_word.unsqueeze(0)], dim=1)\n                \n                if next_word.item() == src_vocab['<eos>']:\n                    break\n            pred_seq = ys[0].tolist()  # shape: [T], removing batch dimension\n            \n            # Remove <sos> if first\n            if len(pred_seq) > 0 and pred_seq[0] == tgt_vocab['<sos>']:\n                pred_seq = pred_seq[1:]\n            # Remove <eos> if last\n            if len(pred_seq) > 0 and pred_seq[-1] == tgt_vocab['<eos>']:\n                pred_seq = pred_seq[:-1]\n            \n            # Convert IDs â†’ string tokens for BLEU\n            pred_tokens = [tgt_vocab.get_itos()[tid] for tid in pred_seq]\n            \n            # 4) Prepare reference\n            ref_seq = tgt[b].tolist()  # shape: [tgt_len] \n            \n            # Remove <sos> if first\n            if len(ref_seq) > 0 and ref_seq[0] == tgt_vocab['<sos>']:\n                ref_seq = ref_seq[1:]\n            # Remove trailing <pad> or <eos>\n            while len(ref_seq) > 0 and ref_seq[-1] in [tgt_vocab['<pad>'], tgt_vocab['<eos>']]:\n                ref_seq.pop()\n    \n            ref_tokens = [tgt_vocab.get_itos()[tid] for tid in ref_seq]\n\n            \n            all_prediction.append(pred_tokens)\n            all_references.append([ref_tokens])\nbleu = calculate_metrics(all_prediction, all_references, pad_idx=tgt_vocab['<pad>'])\n            \n            \n            \n            \n        \n\n    \n    \nprint(f\"BLEU Score: {bleu:.2f}\")\n    \n    # Log to wandb\nwandb.log({\n        \n        \"test_bleu\": bleu\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:08:45.228366Z","iopub.execute_input":"2025-03-06T05:08:45.228667Z","iopub.status.idle":"2025-03-06T05:19:50.999676Z","shell.execute_reply.started":"2025-03-06T05:08:45.228637Z","shell.execute_reply":"2025-03-06T05:19:50.998601Z"}},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [11:03<00:00,  3.71s/it]\n","output_type":"stream"},{"name":"stdout","text":"BLEU Score: 0.16\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-115-22a8f9320bed>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m wandb.log({\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;34m\"test_bleu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maverage_bleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     })\n","\u001b[0;31mNameError\u001b[0m: name 'average_bleu' is not defined"],"ename":"NameError","evalue":"name 'average_bleu' is not defined","output_type":"error"}],"execution_count":115},{"cell_type":"code","source":"bleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:22:26.258556Z","iopub.execute_input":"2025-03-06T05:22:26.258901Z","iopub.status.idle":"2025-03-06T05:22:26.263775Z","shell.execute_reply.started":"2025-03-06T05:22:26.258875Z","shell.execute_reply":"2025-03-06T05:22:26.262940Z"}},"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"0.15994003415107727"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"def translate(model, src_sentence, src_tokenizer, src_vocab, tgt_vocab, device, max_len=50):\n    model.eval()\n    with torch.no_grad():\n        # Tokenize using your tokenizer\n        src_tokens = [token.text for token in src_tokenizer(src_sentence)]\n        \n        # Convert to indices\n        src_indices = [src_vocab[token] for token in src_tokens]\n        src_tensor = torch.LongTensor([src_indices]).to(device)\n        \n        # Create mask\n        src_mask = (src_tensor != src_vocab['<pad>']).unsqueeze(-2)\n        \n        # Encode\n        memory = model.encode(src_tensor, src_mask)\n        \n        # Initialize with <sos>\n        ys = torch.ones(1, 1).fill_(src_vocab['<sos>']).type_as(src_tensor)\n        \n        for i in range(max_len-1):\n            tgt_mask = subsequent_mask(ys.size(1)).to(device)\n            out = model.decode(memory, src_mask, ys, tgt_mask)\n            prob = model.generator(out[:, -1])\n            _, next_word = torch.max(prob, dim=1)\n            ys = torch.cat([ys, next_word.unsqueeze(0)], dim=1)\n            \n            if next_word.item() == src_vocab['<eos>']:\n                break\n                \n        # Convert indices back to tokens\n        translated_tokens = []\n        for idx in ys[0].cpu().numpy():\n            token = tgt_vocab.get_itos()[idx]\n            if token in ['<sos>', '<eos>', '<pad>']:\n                continue\n            translated_tokens.append(token)\n                \n        return \" \".join(translated_tokens)\n\n# Test it\ntest_sentences = [\n    \"Wie geht es dir?\",\n    \"Ich liebe dich\",\n    \"Guten Morgen\"\n]\n\nfor sent in test_sentences:\n    print(f\"Source: {sent}\")\n    print(f\"Translation: {translate(model, sent, de_tokenizer, src_vocab, tgt_vocab, device)}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T05:32:28.627890Z","iopub.execute_input":"2025-03-06T05:32:28.628203Z","iopub.status.idle":"2025-03-06T05:32:28.855565Z","shell.execute_reply.started":"2025-03-06T05:32:28.628164Z","shell.execute_reply":"2025-03-06T05:32:28.854859Z"}},"outputs":[{"name":"stdout","text":"Source: Wie geht es dir?\nTranslation: What 's you going to do it ?\n\nSource: Ich liebe dich\nTranslation: I love you love you .\n\nSource: Guten Morgen\nTranslation: Your morning morning .\n\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"# def load_checkpoint(filepath, model, optimizer=None):\n#     checkpoint = torch.load(filepath)\n#     model.load_state_dict(checkpoint['model_state_dict'])\n#     if optimizer is not None:\n#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n#     return checkpoint['epoch'], checkpoint['loss']\n\n# # Usage:\n# epoch, loss = load_checkpoint('checkpoints/checkpoint_best.pt', model, optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T07:09:02.399432Z","iopub.status.idle":"2025-03-02T07:09:02.399729Z","shell.execute_reply":"2025-03-02T07:09:02.399625Z"}},"outputs":[],"execution_count":null}]}